{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "692342a673de4bbfad8550e8ad6b6b6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2757cba927a64d33a82c702314b7bf79",
              "IPY_MODEL_b9b8390742e44e4d9ca4a72a99065214",
              "IPY_MODEL_7cf079080aab44919c1ee99be551ca21"
            ],
            "layout": "IPY_MODEL_135a0ca330e945d180a5eb8cf722ffa6"
          }
        },
        "2757cba927a64d33a82c702314b7bf79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e6c051bcbf343f7967ce1b0ae506ee2",
            "placeholder": "​",
            "style": "IPY_MODEL_4968b7ab55e04a63be1658c5434d4175",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "b9b8390742e44e4d9ca4a72a99065214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ee2af8e674443d490a5a77de8bd2b36",
            "max": 7305,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_010be8bb903c453da11034d7df098987",
            "value": 7305
          }
        },
        "7cf079080aab44919c1ee99be551ca21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bc40747883d491ea2b9b2c811bab031",
            "placeholder": "​",
            "style": "IPY_MODEL_e3c17a706e7b42ef9dfbee5c7171450f",
            "value": " 7.30k/7.30k [00:00&lt;00:00, 347kB/s]"
          }
        },
        "135a0ca330e945d180a5eb8cf722ffa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e6c051bcbf343f7967ce1b0ae506ee2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4968b7ab55e04a63be1658c5434d4175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ee2af8e674443d490a5a77de8bd2b36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "010be8bb903c453da11034d7df098987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6bc40747883d491ea2b9b2c811bab031": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3c17a706e7b42ef9dfbee5c7171450f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39ac14d2eecf4d1b94f4157653f605e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e47da7f0aa9647ff83558382f490bf43",
              "IPY_MODEL_a03a01ba85364d3c8e3543624b068a2c",
              "IPY_MODEL_38b9b078a8d248dd8185a82d6be47ab6"
            ],
            "layout": "IPY_MODEL_62751c60f0ae41f79f238f45b270ae54"
          }
        },
        "e47da7f0aa9647ff83558382f490bf43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eca0327af09d43278906d9d28c77689c",
            "placeholder": "​",
            "style": "IPY_MODEL_c3299d62a56448f5a2c85b9701755a04",
            "value": "vocab.json: 100%"
          }
        },
        "a03a01ba85364d3c8e3543624b068a2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25a3f5763bb74bc69d3598bddb6c4399",
            "max": 2776833,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_63a47e0a60854f649be6ef33b3f34b19",
            "value": 2776833
          }
        },
        "38b9b078a8d248dd8185a82d6be47ab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc8542fafd4c400589d69a9fac85bd3c",
            "placeholder": "​",
            "style": "IPY_MODEL_55697755c0bf4b8ba13aa465b1ce2b6a",
            "value": " 2.78M/2.78M [00:00&lt;00:00, 10.8MB/s]"
          }
        },
        "62751c60f0ae41f79f238f45b270ae54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eca0327af09d43278906d9d28c77689c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3299d62a56448f5a2c85b9701755a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25a3f5763bb74bc69d3598bddb6c4399": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63a47e0a60854f649be6ef33b3f34b19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc8542fafd4c400589d69a9fac85bd3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55697755c0bf4b8ba13aa465b1ce2b6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "210e1dcb921c4ebd9fcb52e83153b56c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_905b2fbb614e41c489b59c044bbfcca6",
              "IPY_MODEL_349a08ae36be49db9e982f504f99c91b",
              "IPY_MODEL_56249c60f1874a86bf176247a5fb9cc8"
            ],
            "layout": "IPY_MODEL_8025b2b81a794e9397707556c88a3763"
          }
        },
        "905b2fbb614e41c489b59c044bbfcca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d3dfc19451d42f69f58f813e7208d58",
            "placeholder": "​",
            "style": "IPY_MODEL_2245625756434470b7a014baf1c4b1bd",
            "value": "merges.txt: 100%"
          }
        },
        "349a08ae36be49db9e982f504f99c91b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fba12dda7e8452282f6ddd0b1a9a181",
            "max": 1671839,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a1ef11c1dd5400787753b0f1b833f0d",
            "value": 1671839
          }
        },
        "56249c60f1874a86bf176247a5fb9cc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36b4a861ce8d4d5987a219a917caffdd",
            "placeholder": "​",
            "style": "IPY_MODEL_c8c252a8409d41b9827986d22a20e5d0",
            "value": " 1.67M/1.67M [00:00&lt;00:00, 22.3MB/s]"
          }
        },
        "8025b2b81a794e9397707556c88a3763": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d3dfc19451d42f69f58f813e7208d58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2245625756434470b7a014baf1c4b1bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0fba12dda7e8452282f6ddd0b1a9a181": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a1ef11c1dd5400787753b0f1b833f0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "36b4a861ce8d4d5987a219a917caffdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8c252a8409d41b9827986d22a20e5d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db6030590bb646ffa2d497cf85ed612a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f5f359a575e34bdd8fb33db4b9488a6c",
              "IPY_MODEL_d916405e599f4b819bd341e85695f4db",
              "IPY_MODEL_beb4af89f0bb4f3f91c29246cb489ef5"
            ],
            "layout": "IPY_MODEL_bc5efee36e954a52b276c4e71d8aeaf0"
          }
        },
        "f5f359a575e34bdd8fb33db4b9488a6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a20ce20b78b462a8487ae0dab4ed083",
            "placeholder": "​",
            "style": "IPY_MODEL_d9d3633d140c4ec6b8c18d753efb66de",
            "value": "tokenizer.json: 100%"
          }
        },
        "d916405e599f4b819bd341e85695f4db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd1f6c65f1344e7b842fa4842c73cc92",
            "max": 7031645,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d7d00db06cbb43abba92d2d9bf604a78",
            "value": 7031645
          }
        },
        "beb4af89f0bb4f3f91c29246cb489ef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccdc5b59b9e941aab284cff302f6ca3e",
            "placeholder": "​",
            "style": "IPY_MODEL_f370eb6435094b9db0c255ae234d45ed",
            "value": " 7.03M/7.03M [00:00&lt;00:00, 15.7MB/s]"
          }
        },
        "bc5efee36e954a52b276c4e71d8aeaf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a20ce20b78b462a8487ae0dab4ed083": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9d3633d140c4ec6b8c18d753efb66de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd1f6c65f1344e7b842fa4842c73cc92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7d00db06cbb43abba92d2d9bf604a78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ccdc5b59b9e941aab284cff302f6ca3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f370eb6435094b9db0c255ae234d45ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDtidZGPvMkc",
        "outputId": "e245cdde-4c84-4edb-e79d-f6440ecafdd6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXjJl-ROwXOq",
        "outputId": "e1d051fb-aadb-4137-c1eb-61960e61b409"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728,
          "referenced_widgets": [
            "692342a673de4bbfad8550e8ad6b6b6d",
            "2757cba927a64d33a82c702314b7bf79",
            "b9b8390742e44e4d9ca4a72a99065214",
            "7cf079080aab44919c1ee99be551ca21",
            "135a0ca330e945d180a5eb8cf722ffa6",
            "8e6c051bcbf343f7967ce1b0ae506ee2",
            "4968b7ab55e04a63be1658c5434d4175",
            "6ee2af8e674443d490a5a77de8bd2b36",
            "010be8bb903c453da11034d7df098987",
            "6bc40747883d491ea2b9b2c811bab031",
            "e3c17a706e7b42ef9dfbee5c7171450f",
            "39ac14d2eecf4d1b94f4157653f605e2",
            "e47da7f0aa9647ff83558382f490bf43",
            "a03a01ba85364d3c8e3543624b068a2c",
            "38b9b078a8d248dd8185a82d6be47ab6",
            "62751c60f0ae41f79f238f45b270ae54",
            "eca0327af09d43278906d9d28c77689c",
            "c3299d62a56448f5a2c85b9701755a04",
            "25a3f5763bb74bc69d3598bddb6c4399",
            "63a47e0a60854f649be6ef33b3f34b19",
            "fc8542fafd4c400589d69a9fac85bd3c",
            "55697755c0bf4b8ba13aa465b1ce2b6a",
            "210e1dcb921c4ebd9fcb52e83153b56c",
            "905b2fbb614e41c489b59c044bbfcca6",
            "349a08ae36be49db9e982f504f99c91b",
            "56249c60f1874a86bf176247a5fb9cc8",
            "8025b2b81a794e9397707556c88a3763",
            "5d3dfc19451d42f69f58f813e7208d58",
            "2245625756434470b7a014baf1c4b1bd",
            "0fba12dda7e8452282f6ddd0b1a9a181",
            "3a1ef11c1dd5400787753b0f1b833f0d",
            "36b4a861ce8d4d5987a219a917caffdd",
            "c8c252a8409d41b9827986d22a20e5d0",
            "db6030590bb646ffa2d497cf85ed612a",
            "f5f359a575e34bdd8fb33db4b9488a6c",
            "d916405e599f4b819bd341e85695f4db",
            "beb4af89f0bb4f3f91c29246cb489ef5",
            "bc5efee36e954a52b276c4e71d8aeaf0",
            "6a20ce20b78b462a8487ae0dab4ed083",
            "d9d3633d140c4ec6b8c18d753efb66de",
            "dd1f6c65f1344e7b842fa4842c73cc92",
            "d7d00db06cbb43abba92d2d9bf604a78",
            "ccdc5b59b9e941aab284cff302f6ca3e",
            "f370eb6435094b9db0c255ae234d45ed"
          ]
        },
        "id": "EHEztYzNtvBE",
        "outputId": "959953cd-ce81-4ca6-bf63-44412578d2a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/7.30k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "692342a673de4bbfad8550e8ad6b6b6d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39ac14d2eecf4d1b94f4157653f605e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "210e1dcb921c4ebd9fcb52e83153b56c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db6030590bb646ffa2d497cf85ed612a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total examples: 68\n",
            "Training examples: 48\n",
            "Validation examples: 6\n",
            "Test examples: 14\n",
            "\n",
            "Token statistics:\n",
            "mean_user_tokens: 131.87\n",
            "mean_assistant_tokens: 86.29\n",
            "mean_total_tokens: 218.16\n",
            "max_total_tokens: 1207.00\n",
            "min_total_tokens: 62.00\n",
            "\n",
            "Example data points:\n",
            "\n",
            "Example 1:\n",
            "User: Based on the research about DeepSeek V3, please answer the following question: What is DeepSeek V3 and why is it significant in the AI industry?...\n",
            "Assistant: DeepSeek V3 is an AI model from the Chinese startup Deepseek that has caused a stir in the AI space due to its impressive performance at a fraction of the training and inference cost compared to compe...\n",
            "\n",
            "Example 2:\n",
            "User: Based on the research about DeepSeek V3, please answer the following question: How did DeepSeek V3 achieve training efficiency compared to other large language models?...\n",
            "Assistant: DeepSeek V3 achieved significant training efficiency through several innovations: 1) Using a Mixture-of-Experts (MoE) architecture where only 37B parameters fire for each token out of the total 671B, ...\n",
            "\n",
            "Example 3:\n",
            "User: Based on the research about DeepSeek V3, please answer the following question: What was the approximate cost of training DeepSeek V3 and how does it compare to other models?...\n",
            "Assistant: The approximate cost of training DeepSeek V3 was around $5.5-5.6 million, which included approximately 2.788 million GPU hours at an estimated rate of $2 per GPU hour. The training used a cluster of 2...\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import re\n",
        "import random\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load tokenizer for token counting\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-3B-Instruct\")\n",
        "\n",
        "def preprocess_document(text):\n",
        "    \"\"\"Clean and preprocess the document text.\"\"\"\n",
        "    # Remove excessive whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    # Remove special characters that might interfere with processing\n",
        "    text = re.sub(r'[^\\w\\s.,;:?!()\\[\\]{}\\-\\'\\\"$%]', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "def extract_sections(text):\n",
        "    \"\"\"Extract main sections from the document.\"\"\"\n",
        "    # Simple section extraction based on patterns in the document\n",
        "    sections = {}\n",
        "\n",
        "    # Extract overview\n",
        "    if \"Deepseek V3: A Game-Changer in A.I. Here's Why It Matters\" in text:\n",
        "        overview_end = text.find(\"So what made Deepseek such a big impact to A.I. ?\")\n",
        "        if overview_end > 0:\n",
        "            sections[\"overview\"] = text[:overview_end].strip()\n",
        "\n",
        "    # Extract significance\n",
        "    significance_start = text.find(\"So what made Deepseek such a big impact to A.I. ?\")\n",
        "    significance_end = text.find(\"Summary of how Deepseek v3 was so efficient at training the frontier model\")\n",
        "    if significance_start > 0 and significance_end > 0:\n",
        "        sections[\"significance\"] = text[significance_start:significance_end].strip()\n",
        "\n",
        "    # Extract model architecture\n",
        "    architecture_start = text.find(\"Model Architecture\")\n",
        "    architecture_end = text.find(\"FP8 Mixed Precision Training:\")\n",
        "    if architecture_start > 0 and architecture_end > 0:\n",
        "        sections[\"architecture\"] = text[architecture_start:architecture_end].strip()\n",
        "\n",
        "    # Extract training approach\n",
        "    training_start = text.find(\"FP8 Mixed Precision Training:\")\n",
        "    training_end = text.find(\"Load Balancing Strategy\")\n",
        "    if training_start > 0 and training_end > 0:\n",
        "        sections[\"training\"] = text[training_start:training_end].strip()\n",
        "\n",
        "    # Extract cost analysis\n",
        "    cost_start = text.find(\"Breakdown of the costs of the Deepseek v3 model\")\n",
        "    if cost_start > 0:\n",
        "        sections[\"cost\"] = text[cost_start:].strip()\n",
        "\n",
        "    return sections\n",
        "\n",
        "def generate_qa_pairs(document, sections):\n",
        "    \"\"\"Generate question-answer pairs from the document.\"\"\"\n",
        "    qa_pairs = []\n",
        "\n",
        "    # General questions about the paper\n",
        "    qa_pairs.extend([\n",
        "        {\n",
        "            \"question\": \"What is DeepSeek V3 and why is it significant in the AI industry?\",\n",
        "            \"answer\": \"DeepSeek V3 is an AI model from the Chinese startup Deepseek that has caused a stir in the AI space due to its impressive performance at a fraction of the training and inference cost compared to competitors. It uses a Mixture-of-Experts (MoE) architecture with 671B parameters but only 37B active parameters per token, which significantly reduces compute requirements. Its significance lies in improving algorithms at the software level rather than pushing for better hardware, making AI development more efficient and potentially disrupting the industry.\",\n",
        "            \"source\": \"overview\"\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"How did DeepSeek V3 achieve training efficiency compared to other large language models?\",\n",
        "            \"answer\": \"DeepSeek V3 achieved significant training efficiency through several innovations: 1) Using a Mixture-of-Experts (MoE) architecture where only 37B parameters fire for each token out of the total 671B, 2) Implementing FP8 mixed precision training which reduced memory usage by up to 50% compared to traditional formats, 3) Developing a custom training framework called HAI-LLM with optimizations like the DualPipe algorithm for efficient pipeline parallelism, 4) Using Multi-head Latent Attention (MLA) to compress the Key-Value cache, 5) Pioneering an auxiliary loss-free strategy for load balancing in the MoE architecture, and 6) Implementing efficient cross-node communication kernels and memory optimizations.\",\n",
        "            \"source\": \"significance,architecture,training\"\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"What was the approximate cost of training DeepSeek V3 and how does it compare to other models?\",\n",
        "            \"answer\": \"The approximate cost of training DeepSeek V3 was around $5.5-5.6 million, which included approximately 2.788 million GPU hours at an estimated rate of $2 per GPU hour. The training used a cluster of 2,048 H800 GPUs and was completed in less than two months. This is significantly more efficient than competitor models like Llama 3.1, which reportedly required 30.84 million GPU hours for training on a similar amount of data (15 trillion tokens vs. DeepSeek's 14.8 trillion tokens).\",\n",
        "            \"source\": \"cost\"\n",
        "        }\n",
        "    ])\n",
        "\n",
        "    # Extract sentences and generate more specific QA pairs\n",
        "    for section_name, section_text in sections.items():\n",
        "        sentences = sent_tokenize(section_text)\n",
        "\n",
        "        if section_name == \"architecture\":\n",
        "            qa_pairs.extend([\n",
        "                {\n",
        "                    \"question\": \"What type of architecture does DeepSeek V3 use?\",\n",
        "                    \"answer\": \"DeepSeek V3 uses a Mixture-of-Experts (MoE) architecture where only 37B parameters fire for each token out of the total 671B parameters. This sparse activation significantly reduces compute requirements compared to dense models. The model also uses Multi-head Latent Attention (MLA) which compresses the Key-Value cache, reducing memory usage and enabling more efficient training.\",\n",
        "                    \"source\": \"architecture\"\n",
        "                },\n",
        "                {\n",
        "                    \"question\": \"How many parameters does DeepSeek V3 have and how many are active during inference?\",\n",
        "                    \"answer\": \"DeepSeek V3 has a total of 671B parameters in its Mixture-of-Experts (MoE) architecture, but only 37B parameters are active (fire) for each token during processing. This sparse activation approach significantly reduces the computational requirements compared to dense models of similar size.\",\n",
        "                    \"source\": \"architecture\"\n",
        "                }\n",
        "            ])\n",
        "\n",
        "        elif section_name == \"training\":\n",
        "            qa_pairs.extend([\n",
        "                {\n",
        "                    \"question\": \"What precision format did DeepSeek V3 use for training and what were its benefits?\",\n",
        "                    \"answer\": \"DeepSeek V3 implemented an FP8 mixed precision training framework, which reduced memory usage and accelerated training compared to higher precision formats. This approach reduced the memory footprint by up to 50% compared to traditional FP16/FP32 formats. They used fine-grained quantization strategies and increased accumulation precision to maintain accuracy while gaining the efficiency benefits.\",\n",
        "                    \"source\": \"training\"\n",
        "                },\n",
        "                {\n",
        "                    \"question\": \"What is the HAI-LLM framework mentioned in the DeepSeek V3 paper?\",\n",
        "                    \"answer\": \"HAI-LLM is a custom training framework developed by DeepSeek for training their V3 model. It includes several optimizations such as the DualPipe algorithm for efficient pipeline parallelism (which reduces pipeline bubbles and overlaps computation and communication), efficient cross-node all-to-all communication kernels to fully utilize network bandwidth, and careful memory optimizations to avoid using costly tensor parallelism.\",\n",
        "                    \"source\": \"training\"\n",
        "                }\n",
        "            ])\n",
        "\n",
        "        elif section_name == \"cost\":\n",
        "            qa_pairs.extend([\n",
        "                {\n",
        "                    \"question\": \"How many GPU hours did it take to train DeepSeek V3?\",\n",
        "                    \"answer\": \"Training DeepSeek V3 took approximately 2.788 million GPU hours in total. This breaks down to 2,664,000 GPU hours for pre-training, 119,000 GPU hours for context length extension, and 5,000 GPU hours for post-training. The training was completed in less than two months using a cluster of 2,048 H800 GPUs.\",\n",
        "                    \"source\": \"cost\"\n",
        "                },\n",
        "                {\n",
        "                    \"question\": \"How many tokens was DeepSeek V3 trained on?\",\n",
        "                    \"answer\": \"DeepSeek V3 was trained on approximately 14.8 trillion high-quality tokens. For perspective, this is comparable to Llama 3.1's 15 trillion tokens, but DeepSeek achieved much greater efficiency in its training process.\",\n",
        "                    \"source\": \"cost\"\n",
        "                }\n",
        "            ])\n",
        "\n",
        "    # Generate more detailed/specific questions based on document content\n",
        "    specific_facts = [\n",
        "        {\n",
        "            \"question\": \"What compression ratio did DeepSeek achieve for key value indices?\",\n",
        "            \"answer\": \"According to the document, DeepSeek compressed key value indices which consume significant VRAM, achieving 93% compression ratios. This was part of their overall approach to make training more efficient.\",\n",
        "            \"source\": \"significance\"\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"What is Multi-head Latent Attention (MLA) and how was it used in DeepSeek V3?\",\n",
        "            \"answer\": \"Multi-head Latent Attention (MLA) is a technique used in DeepSeek V3 that compresses the Key-Value cache. This reduces memory usage and enables more efficient training by decreasing the memory footprint required during model operation.\",\n",
        "            \"source\": \"architecture\"\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"How does DeepSeek V3 perform at reasoning and math compared to other models?\",\n",
        "            \"answer\": \"According to the document, DeepSeek V3 excels at reasoning and math tasks, surpassing the performance of GPT-4 and Claude 3.5 Sonnet in these areas. For writing and coding tasks, however, Claude 3.5 Sonnet maintains a slight lead over DeepSeek V3.\",\n",
        "            \"source\": \"cost\"\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"What was DeepSeek's approach to load balancing in their MoE architecture?\",\n",
        "            \"answer\": \"DeepSeek pioneered an auxiliary loss-free strategy for load balancing in their Mixture-of-Experts (MoE) architecture. This improved performance without the drawbacks of traditional auxiliary loss methods that are typically used in MoE architectures.\",\n",
        "            \"source\": \"training\"\n",
        "        }\n",
        "    ]\n",
        "    qa_pairs.extend(specific_facts)\n",
        "\n",
        "    # Generate comparative questions\n",
        "    comparative_questions = [\n",
        "        {\n",
        "            \"question\": \"How does the training efficiency of DeepSeek V3 compare to Llama 3.1?\",\n",
        "            \"answer\": \"DeepSeek V3 was significantly more efficient in training compared to Llama 3.1. While DeepSeek V3 required about 2.788 million GPU hours to train on 14.8 trillion tokens, Llama 3.1 reportedly required 30.84 million GPU hours to train on a similar amount of data (15 trillion tokens). This means DeepSeek V3 was approximately 11 times more efficient than Llama 3.1 in terms of GPU hours required for training.\",\n",
        "            \"source\": \"cost\"\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"What are the key differences between DeepSeek's approach and that of other AI companies?\",\n",
        "            \"answer\": \"The key difference in DeepSeek's approach compared to other AI companies is that while others pushed for better hardware, DeepSeek focused on improving algorithms, achieving better results at a software level. Specifically, they made training 45 times more efficient by: using 8-bit instead of 32-bit to save memory, compressing key value indices with 93% compression ratios, implementing multi-token prediction instead of single-token prediction (doubling inference speeds), and using a Mixture-of-Experts model that decomposes a big model into small models capable of running on consumer-grade hardware.\",\n",
        "            \"source\": \"significance\"\n",
        "        }\n",
        "    ]\n",
        "    qa_pairs.extend(comparative_questions)\n",
        "\n",
        "    # Generate application and future-focused questions\n",
        "    application_questions = [\n",
        "        {\n",
        "            \"question\": \"What potential impact could DeepSeek V3's efficient approach have on the AI industry?\",\n",
        "            \"answer\": \"DeepSeek V3's efficient approach could have several significant impacts on the AI industry: 1) It could democratize access to powerful AI by reducing the hardware requirements and costs, 2) It could accelerate AI development by enabling faster training cycles, 3) It could shift industry focus from hardware scaling to algorithmic efficiency, 4) It might lead to more environmentally sustainable AI by reducing energy consumption, and 5) It could disrupt the market dominance of major US tech companies, as evidenced by the market concerns and impact on share prices mentioned in the document.\",\n",
        "            \"source\": \"overview,significance\"\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"How might the techniques used in DeepSeek V3 be applied to smaller models or different domains?\",\n",
        "            \"answer\": \"The techniques used in DeepSeek V3 could be applied to smaller models or different domains in several ways: 1) The Mixture-of-Experts architecture could help create more efficient smaller models by activating only relevant parameters, 2) FP8 mixed precision training could reduce memory requirements for models of any size, 3) The Key-Value cache compression techniques could improve efficiency in models designed for limited hardware, 4) Multi-token prediction could speed up inference across various applications, and 5) The custom training framework optimizations could benefit any distributed training setup regardless of model size or application domain.\",\n",
        "            \"source\": \"architecture,training,significance\"\n",
        "        }\n",
        "    ]\n",
        "    qa_pairs.extend(application_questions)\n",
        "\n",
        "    return qa_pairs\n",
        "\n",
        "def create_instruction_dataset(qa_pairs):\n",
        "    \"\"\"Convert QA pairs to instruction format for fine-tuning.\"\"\"\n",
        "    dataset = []\n",
        "\n",
        "    for pair in qa_pairs:\n",
        "        # Format for Qwen2.5 Instruct model\n",
        "        instruction = {\n",
        "            \"conversations\": [\n",
        "                {\"role\": \"user\", \"content\": f\"Based on the research about DeepSeek V3, please answer the following question: {pair['question']}\"},\n",
        "                {\"role\": \"assistant\", \"content\": pair['answer']}\n",
        "            ]\n",
        "        }\n",
        "        dataset.append(instruction)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# Load the document\n",
        "document_text = \"\"\"author - Visith Kumarapperuma\n",
        "\n",
        "Deepseek V3: A Game-Changer in A.I. Here's Why It Matters\n",
        "Currently, the AI models from the Chinese startup Deepseek are causing quite a stir in the AI space. Their latest reasoning model, Deepseek r1, shows better or equal performance to competitors. But above all, they achieved it with a fraction of the training and inference cost. DeepSeek's AI Assistant overtook ChatGPT to become the most downloaded free app on the U.S. App Store. This development has led to market concerns about A.I. investments to major U.S. tech companies. Impacting share prices of tech firms including Nvidia.\n",
        "\n",
        "So what made Deepseek such a big impact to A.I. ?\n",
        "The significance of Deepseek as a disruptor in the industry lies in its approach. Unlike other companies that pushed for better hardware, Deepseek improved the algorithms. Thus achieving better results at a software level. Note that the following details are for the Deepseek V3 model. • Deepseek said it trained a model using a data centre of some 2,000 of Nvidia H800 GPUs. • Time duration 2 months with the cost of the *final training run being ~$5.5 million This ~$5.5M reflects the \"rental\" cost for the GPU hours needed to train DeepSeek‑V3. It does not include:\n",
        "\n",
        "The capital expenditure for owning the hardware.\n",
        "Costs associated with prior research, ablation studies, or experiments on alternative architectures/algorithms/data.\n",
        "Deepseek made training more efficient (45 times more efficient)\n",
        "Use 8-bit instead of 32-bit to save memory.\n",
        "Compress key value indices which eat up a lot of VRAM; they got 93% compression ratios.\n",
        "Do multi-token prediction instead of single-token prediction -> doubled inference speeds\n",
        "The MOE model decomposes a big model into small models that can run on consumer-grade hardware.\n",
        "Summary of how Deepseek v3 was so efficient at training the frontier model\n",
        "Model Architecture The model employs a Mixture-of-Experts (MoE) architecture, where only 37B parameters fire for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models. The model uses Multi-head Latent Attention (MLA). This compresses the Key-Value cache, reducing memory usage and enabling more efficient training.\n",
        "FP8 Mixed Precision Training: They implemented an FP8 mixed precision training framework. Which reduces memory usage and accelerates training compared to higher precision formats. Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats. They use fine-grained quantisation strategies and increased accumulation precision to maintain accuracy.\n",
        "Load Balancing Strategy They pioneered an auxiliary loss-free strategy for load balancing in the MoE architecture. This improved performance without the drawbacks of traditional auxiliary loss methods.\n",
        "Training Framework They developed a custom training framework called HAI-LLM with several optimisations: DualPipe algorithm for efficient pipeline parallelism. This reduces pipeline bubbles and overlapping computation and communication. Efficient cross-node all-to-all communication kernels to fully utilise network bandwidth. Careful memory optimisations to avoid using costly tensor parallelism.\n",
        "Breakdown of the costs of the Deepseek v3 model\n",
        "Deepseek's flagship model v3 showcases an architecture with a 671B parameter MOE (Mixture of Agents) with 37B active parameters per token\n",
        "\n",
        "Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework.\n",
        "Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet.\n",
        "For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead.\n",
        "Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million\n",
        "the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. So how true is the claim of $5.5 million, or is it another marketing trick?\n",
        "Underlying FLOP calculations Model Details:\n",
        "Active Parameters: 37B (using FP8 precision)\n",
        "FLOPs per token: Using the rule of thumb \"6 FLOPs per parameter per token.\" 37B×6 = 222B FLOPs per token\n",
        "Total Training Tokens: Approximately 14.8 trillion tokens\n",
        "Total FLOPs required: 222 B FLOPs/token×14.8 T tokens ≈ 3.3×10²⁴ FLOPs\n",
        "GPU FLOP Capacity (H800/H100):\n",
        "An H100 is roughly estimated to deliver about. 3.958×10¹⁵ FLOPs (per second or per some standardised interval — here used as a comparative metric). Ideal (Perfect Efficiency) GPU hours. (Dividing total required FLOPs by per‑GPU capability gives) 3.3×10²⁴ / 3.958×10¹⁵ ​≈ 8.33×10⁸ seconds⇒≈0.4 million GPU hour Note: This \"perfect efficiency\" scenario is a lower bound. Real-world training is less efficient. 2. Adjusting for Real‑World Inefficiencies (Comparison with Llama 3.1) Reference Model: Llama 3.1 (405B parameters, 15 T tokens) reportedly required 30.84 M GPU hours in practice. Recalculating FLOPs for Llama 3.1: Using the same math: 3.64×10²⁵ FLOPs required Scaling Efficiency Using the ratio of FLOPs needed for DeepSeek‑V3 versus Llama 3.1. and assuming similar inefficiencies. The estimate adjusts to roughly 2.79M GPU hours for DeepSeek‑V3 training. 3. DeepSeek‑V3 Reported Training Breakdown According to the DeepSeek‑V3 paper Pre‑training Stage:\n",
        "\n",
        "Per Trillion Tokens: 180K H800 GPU hours\n",
        "Overall Pre‑training: Total of 2,664K GPU hours\n",
        "This stage was completed in less than two months using a cluster of 2,048 H800 GPUs. Context Length Extension:\n",
        "Additional 119K GPU hours Post‑training:\n",
        "An extra 5K GPU hours Total GPU Hours: 2,664 K+119 K+5 K≈2.788M GPU hours\n",
        "Cost Estimation Assumed GPU Rental Price: $2 per GPU hour Total Rental Cost: 2.788M GPU hours×$2/hour≈$5.576 million as stated in Deepseek paper During the pre‑training stage, training DeepSeek‑V3 on each trillion tokens requires only 180K H800 GPU hours… Consequently, our pre‑training stage is completed in less than two months and costs 2664K GPU hours. Combined with 119K GPU hours for the context length extension and 5K GPU hours for post‑training, DeepSeek‑V3 costs only 2.788M GPU hours for its full training. Assuming the rental price of the H800 GPU is $2 per GPU hour, our total training costs amount to only $5.576M.\n",
        "Summary Theoretical (Perfect Efficiency) Estimate: ~0.4 M GPU hours (using idealised FLOP counts and assuming perfect hardware utilisation0 Adjusted (Real‑World) Estimate (via Llama 3.1 comparison): ~2.79 GPU hours DeepSeek‑V3 Reported Breakdown: Pre‑training: 2,664K GPU hours Context Extension: 119K GPU hours Post‑training: 5K GPU hours Total: ~2.788 M GPU hours\n",
        "Cost (at $2 per GPU hour): ~$5.576 million\"\"\"\n",
        "\n",
        "# Clean the document\n",
        "clean_doc = preprocess_document(document_text)\n",
        "\n",
        "# Extract sections\n",
        "doc_sections = extract_sections(clean_doc)\n",
        "\n",
        "# Generate question-answer pairs\n",
        "qa_pairs = generate_qa_pairs(clean_doc, doc_sections)\n",
        "\n",
        "# Convert to instruction format\n",
        "instruction_dataset = create_instruction_dataset(qa_pairs)\n",
        "\n",
        "# Augment data by creating variations\n",
        "def augment_data(dataset, augmentation_factor=2):\n",
        "    augmented_dataset = dataset.copy()\n",
        "    question_variations = [\n",
        "        \"Can you tell me about {}?\",\n",
        "        \"Please explain {}.\",\n",
        "        \"I'd like to know more about {}.\",\n",
        "        \"What information do you have on {}?\",\n",
        "        \"Could you elaborate on {}?\",\n",
        "        \"What does the research say about {}?\"\n",
        "    ]\n",
        "\n",
        "    for _ in range(augmentation_factor - 1):\n",
        "        for item in dataset:\n",
        "            original_question = item[\"conversations\"][0][\"content\"]\n",
        "            # Extract the core question by removing the prefix\n",
        "            core_question = original_question.replace(\"Based on the research about DeepSeek V3, please answer the following question: \", \"\")\n",
        "\n",
        "            # Create a new variation\n",
        "            template = random.choice(question_variations)\n",
        "            new_question = f\"Based on the DeepSeek V3 research paper, {template.format(core_question.lower().rstrip('?'))}\"\n",
        "\n",
        "            # Create a new data point\n",
        "            new_item = {\n",
        "                \"conversations\": [\n",
        "                    {\"role\": \"user\", \"content\": new_question},\n",
        "                    {\"role\": \"assistant\", \"content\": item[\"conversations\"][1][\"content\"]}\n",
        "                ]\n",
        "            }\n",
        "            augmented_dataset.append(new_item)\n",
        "\n",
        "    return augmented_dataset\n",
        "\n",
        "# Augment the dataset\n",
        "augmented_dataset = augment_data(instruction_dataset, augmentation_factor=3)\n",
        "\n",
        "# Generate additional training examples with RAG context format\n",
        "def create_rag_format_examples(qa_pairs, doc_sections):\n",
        "    rag_examples = []\n",
        "\n",
        "    for pair in qa_pairs:\n",
        "        source_section = pair.get(\"source\", \"\").split(\",\")[0]\n",
        "        context = doc_sections.get(source_section, \"\")\n",
        "\n",
        "        if context:\n",
        "            # Format for RAG scenario where context is provided\n",
        "            instruction = {\n",
        "                \"conversations\": [\n",
        "                    {\"role\": \"user\", \"content\": f\"\"\"Here is information about DeepSeek V3:\n",
        "\n",
        "{context}\n",
        "\n",
        "Based on this information, please answer: {pair['question']}\"\"\"},\n",
        "                    {\"role\": \"assistant\", \"content\": pair['answer']}\n",
        "                ]\n",
        "            }\n",
        "            rag_examples.append(instruction)\n",
        "\n",
        "    return rag_examples\n",
        "\n",
        "# Create RAG-format examples\n",
        "rag_examples = create_rag_format_examples(qa_pairs, doc_sections)\n",
        "\n",
        "# Combine all examples\n",
        "combined_dataset = augmented_dataset + rag_examples\n",
        "\n",
        "# Function to calculate token counts for dataset assessment\n",
        "def calculate_token_count(text):\n",
        "    return len(tokenizer.encode(text))\n",
        "\n",
        "# Calculate token statistics\n",
        "token_counts = []\n",
        "for item in combined_dataset:\n",
        "    user_msg = item[\"conversations\"][0][\"content\"]\n",
        "    assistant_msg = item[\"conversations\"][1][\"content\"]\n",
        "    token_counts.append({\n",
        "        \"user_tokens\": calculate_token_count(user_msg),\n",
        "        \"assistant_tokens\": calculate_token_count(assistant_msg),\n",
        "        \"total_tokens\": calculate_token_count(user_msg) + calculate_token_count(assistant_msg)\n",
        "    })\n",
        "\n",
        "token_df = pd.DataFrame(token_counts)\n",
        "token_stats = {\n",
        "    \"mean_user_tokens\": token_df[\"user_tokens\"].mean(),\n",
        "    \"mean_assistant_tokens\": token_df[\"assistant_tokens\"].mean(),\n",
        "    \"mean_total_tokens\": token_df[\"total_tokens\"].mean(),\n",
        "    \"max_total_tokens\": token_df[\"total_tokens\"].max(),\n",
        "    \"min_total_tokens\": token_df[\"total_tokens\"].min()\n",
        "}\n",
        "\n",
        "# Split into train, validation, and test sets\n",
        "train_data, test_data = train_test_split(combined_dataset, test_size=0.2, random_state=42)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.1, random_state=42)\n",
        "\n",
        "# Save the datasets to JSON files\n",
        "with open(\"train_data.json\", \"w\") as f:\n",
        "    json.dump(train_data, f, indent=2)\n",
        "\n",
        "with open(\"val_data.json\", \"w\") as f:\n",
        "    json.dump(val_data, f, indent=2)\n",
        "\n",
        "with open(\"test_data.json\", \"w\") as f:\n",
        "    json.dump(test_data, f, indent=2)\n",
        "\n",
        "# Print dataset statistics\n",
        "print(f\"Total examples: {len(combined_dataset)}\")\n",
        "print(f\"Training examples: {len(train_data)}\")\n",
        "print(f\"Validation examples: {len(val_data)}\")\n",
        "print(f\"Test examples: {len(test_data)}\")\n",
        "print(\"\\nToken statistics:\")\n",
        "for key, value in token_stats.items():\n",
        "    print(f\"{key}: {value:.2f}\")\n",
        "\n",
        "# Generate a few examples for review\n",
        "print(\"\\nExample data points:\")\n",
        "for i in range(min(3, len(combined_dataset))):\n",
        "    print(f\"\\nExample {i+1}:\")\n",
        "    print(f\"User: {combined_dataset[i]['conversations'][0]['content'][:200]}...\")\n",
        "    print(f\"Assistant: {combined_dataset[i]['conversations'][1]['content'][:200]}...\")"
      ]
    }
  ]
}